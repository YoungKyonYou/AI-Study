{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor \n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터를 sklearn에서 가져와보자\n",
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터는 california housing 데이터를 사용한다.\n",
    "california=fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'feature_names', 'DESCR'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "california.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 20640\\n\\n    :Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n    :Attribute Information:\\n        - MedInc        median income in block\\n        - HouseAge      median house age in block\\n        - AveRooms      average number of rooms\\n        - AveBedrms     average number of bedrooms\\n        - Population    block population\\n        - AveOccup      average house occupancy\\n        - Latitude      house block latitude\\n        - Longitude     house block longitude\\n\\n    :Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttp://lib.stat.cmu.edu/datasets/\\n\\nThe target variable is the median house value for California districts.\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. topic:: References\\n\\n    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n      Statistics and Probability Letters, 33 (1997) 291-297\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "california['DESCR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X와 y로 나눈다\n",
    "X=california['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=california['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#내가 보기 편안한 dataframe으로 변경해줌.\n",
    "X=pd.DataFrame(X,columns=california['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.DataFrame(y,columns=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train 데이터와 test 데이터를 split 한다.\n",
    "train_X, test_X, train_y, test_y=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning rate\n",
    "lr=0.1\n",
    "n_est=250\n",
    "max_depth=10\n",
    "reg_lambda=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr=xgb.XGBRegressor(learning_rate=lr,n_estimators=n_est,max_depth=max_depth, reg_lambda=reg_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_estimators 디폴트는 100인데 비교해보려고 설정한다.\n",
    "gb=GradientBoostingRegressor(learning_rate=lr,n_estimators=n_est,max_depth=max_depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit를 한다\n",
    "trained_xgb=xgbr.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nick1\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "trained_gb=gb.fit(train_X,train_y)\n",
    "#train를 했으면 predict를 한다. predict를 왜하려고 할까?\n",
    "#train 데이터도 확인해 봐야한다. overfitting, underfitting 할 때 train 데이터도\n",
    "#예측이 안되면 학습이 안 됐으니까 파라미터를 다시 해줘야 한다 그지?\n",
    "#그래서 train data도 performance score를 확인해 보고 test data도 performance score를 확인해\n",
    "#봐야 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#그래서 predict를 해본다.\n",
    "trained_pred_xgb=trained_xgb.predict(train_X)\n",
    "trained_pred_gb=trained_gb.predict(train_X)\n",
    "test_pred_xgb=trained_xgb.predict(test_X)\n",
    "test_pred_gb=trained_gb.predict(test_X)\n",
    "#이제 performance 측정을 해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean_squared_error, r2_score를 측정해본다.\n",
    "\n",
    "trained_mse_xgb=mean_squared_error(trained_pred_xgb,train_y)\n",
    "trained_mse_gb=mean_squared_error(trained_pred_gb,train_y)\n",
    "trained_r2_xgb=r2_score(trained_pred_xgb,train_y)\n",
    "trained_r2_gb=r2_score(trained_pred_gb,train_y)\n",
    "\n",
    "test_mse_xgb=mean_squared_error(test_pred_xgb,test_y)\n",
    "test_mse_gb=mean_squared_error(test_pred_gb,test_y)\n",
    "test_r2_xgb=r2_score(test_pred_xgb,test_y)\n",
    "test_r2_gb=r2_score(test_pred_gb, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 0.005-->0.006\n",
      "Train rw: 0.996-->0.995\n",
      "Test MSE: 0.222-->0.213\n",
      "Test rw: 0.798-->0.805\n"
     ]
    }
   ],
   "source": [
    "#이제 확인을 해보자\n",
    "\n",
    "print('Train MSE: {:.3f}-->{:.3f}'.format(trained_mse_gb,trained_mse_xgb))\n",
    "print('Train rw: {:.3f}-->{:.3f}'.format(trained_r2_gb,trained_r2_xgb))\n",
    "\n",
    "print('Test MSE: {:.3f}-->{:.3f}'.format(test_mse_gb,test_mse_xgb))\n",
    "print('Test rw: {:.3f}-->{:.3f}'.format(test_r2_gb,test_r2_xgb))\n",
    "\n",
    "#Train MSE: 0.309-->0.311\n",
    "#Train rw: 0.643-->0.641\n",
    "#Test MSE: 0.333-->0.335\n",
    "#Test rw: 0.598-->0.597\n",
    "#결과를 보니 train도 마찬가지고 test도 마찬가지고 거의 비슷하거나 조금더 xgb 성능이 조금 더\n",
    "#안 좋게 보인다.\n",
    "#여기서 질문!\n",
    "#결과가 나왔는데 xgboosting이 안좋아서 이렇게 나올까?\n",
    "#xgb가 gb에 비해 특징이 뭘까?\n",
    "#다른 점이 뭘까 \n",
    "#오버피팅을 막을 수 있을 것 같다. 그럼 거기에 포인트가 있다고 하면\n",
    "#오버피팅은 언제 생기나? 부스팅 계열에서 오버피팅은 언제 생길까?\n",
    "#계속해서 학습하게 되면 생긴다. 그러니까 모델이 복잡해지면 생긴다. \n",
    "#그럼 그것을 막기 위한 방법으로 xgb 에서는 regularization 테크닉이 있었다.\n",
    "#지금 보니까 R2가 0.59이다. 어느 정도 데이터가 어려운 데이터는 아니다 그래서\n",
    "#큰 차이가 없을 수도 있는데 지금보다는 예측을 더 잘할 수 있을 것 같다.\n",
    "#근데 너무 학습 시키면 오버피팅이 될 수 있는데 한번 그렇게 만들어보자. 위에서\n",
    "#n_est=50로 설정해줬었는데 한 번 늘려보자. 250개로 늘려보자.\n",
    "#그랬더니 이렇게 나온다\n",
    "#Train MSE: 0.211-->0.212\n",
    "#Train rw: 0.803-->0.802\n",
    "#Test MSE: 0.248-->0.247\n",
    "#Test rw: 0.757-->0.759\n",
    "#큰차이가 안 났다 한번 max_depth를 늘려봐야 겠다.\n",
    "#3->10으로 늘려본다.\n",
    "#max_depth를 좀 올려가지고 비교했는데 \n",
    "#Train MSE: 0.005-->0.005\n",
    "#Train rw: 0.996-->0.996\n",
    "#train에 대해서는 같게 나오고\n",
    "#Test MSE: 0.223-->0.215\n",
    "#Test rw: 0.797-->0.803\n",
    "#test에서 역전됐다.\n",
    "#xgboosting이 조금 더 좋게 나오는 것 같다.\n",
    "#(MSE는 작으면 작을 수록 좋다.)\n",
    "#일단 보니까 오버피팅이 발생했는데 gb가 더 크게 발생한거 같고 xgb는 조금 더 완화시켜 준 것 같다.\n",
    "#조금 더 다르게 해보자 reg_lambday를 0.1->0.3으로 늘려보자.\n",
    "#이렇게 결과를 내고 이런 결과를 가지고 결론을 내면 될까?\n",
    "#추가적으로 뭘할 수 있을까?\n",
    "#교수님이라면 지금 데이터가 쉬워서 큰 차이가 없을 거 같은데\n",
    "#교수님이라면 \n",
    "#1번: Train & Test 데이터를 좀 더 다양하게 확인해 본다.\n",
    "#좀 더 다양하게 하기 위한 방법은\n",
    "#Train과 Test를 여러 번 해보겠다.(평균 에러를 쓴다)\n",
    "#어떻게 해보냐면 random state를 바꿔서 여러 번 해보거나 또는 \n",
    "#우리가 지금 파라미터가 많은데 이 파라미터가 많으니까 이 파라미터의 최적을 설정해서\n",
    "#비교해 보는 것이다. 즉 cross-validation를 해보는 것이다. 그리고 이 cross-validation에서\n",
    "#나오는 test 에러를 쓴다. \n",
    "#5 CV를 보면 데이터를 5개로 쪼개고 각각 그 5개를 train도 하고 test도 하는데\n",
    "#그 5개의 test error의 평균 에러를 쓰겠다(교수님이)\n",
    "#3번 Train/Test 비율를 여러 가지고 나눠서 해본다.\n",
    "#4번 Performance measure도 여러 개를 써서 비교해 본다. \n",
    "#이정도는 해봐야 하는 것이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
